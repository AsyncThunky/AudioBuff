{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import platform\n",
        "import subprocess\n",
        "import torch\n",
        "\n",
        "print(f\"Python: {platform.python_version()}\")\n",
        "print(f\"Platform: {platform.platform()}\")\n",
        "print(f\"Torch: {torch.__version__}\")\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    raise RuntimeError(\"CUDA GPU not detected. In Colab, enable GPU: Runtime -> Change runtime type -> GPU\")\n",
        "\n",
        "print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "subprocess.run([\"nvidia-smi\"], check=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "REPO_URL = \"https://github.com/AsyncThunky/AudioBuff.git\"\n",
        "BRANCH = \"main\"\n",
        "DRIVE_ROOT = \"/content/drive/MyDrive/AudioBuff\"\n",
        "PROFILE = \"smoke\"  # smoke | poc | full\n",
        "XCODEC_GIT_URL = \"\"  # Optional: e.g. https://github.com/your-fork/xcodec.git\n",
        "\n",
        "RUN_PREP = True\n",
        "RUN_TRAIN = True\n",
        "RUN_INFER = True\n",
        "\n",
        "RAW_AUDIO_DIR = \"/content/drive/MyDrive/AudioBuff/raw_pristine_audio\"\n",
        "INFER_INPUT_WAV = \"\"  # Optional explicit input wav path\n",
        "\n",
        "RESUME_FROM_LATEST = True\n",
        "DAC_MODEL_TYPE = \"44khz\"\n",
        "SEED = 1337\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DRIVE_ROOT_PATH = Path(DRIVE_ROOT)\n",
        "PERSIST_LATENTS = DRIVE_ROOT_PATH / \"latents\"\n",
        "PERSIST_CHECKPOINTS = DRIVE_ROOT_PATH / \"checkpoints\"\n",
        "PERSIST_ARTIFACTS = DRIVE_ROOT_PATH / \"artifacts\"\n",
        "\n",
        "for directory in (DRIVE_ROOT_PATH, PERSIST_LATENTS, PERSIST_CHECKPOINTS, PERSIST_ARTIFACTS):\n",
        "    directory.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Drive root: {DRIVE_ROOT_PATH}\")\n",
        "print(f\"Latents: {PERSIST_LATENTS}\")\n",
        "print(f\"Checkpoints: {PERSIST_CHECKPOINTS}\")\n",
        "print(f\"Artifacts: {PERSIST_ARTIFACTS}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "REPO_DIR = Path(\"/content/AudioBuff\")\n",
        "\n",
        "\n",
        "def run(cmd: list[str], cwd: Path | None = None) -> None:\n",
        "    print(\"+\", \" \".join(str(x) for x in cmd))\n",
        "    subprocess.run(cmd, check=True, cwd=str(cwd) if cwd else None)\n",
        "\n",
        "if REPO_DIR.exists():\n",
        "    shutil.rmtree(REPO_DIR)\n",
        "\n",
        "run([\"git\", \"clone\", \"--depth\", \"1\", \"--branch\", BRANCH, REPO_URL, str(REPO_DIR)])\n",
        "run([\"python\", \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\"], cwd=REPO_DIR)\n",
        "run([\"python\", \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\"], cwd=REPO_DIR)\n",
        "\n",
        "if XCODEC_GIT_URL.strip():\n",
        "    run([\"python\", \"-m\", \"pip\", \"install\", f\"git+{XCODEC_GIT_URL.strip()}\"], cwd=REPO_DIR)\n",
        "else:\n",
        "    print(\"XCODEC_GIT_URL is empty. Training/inference will use the built-in random fallback conditioning.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def must_contain(path: Path, tokens: list[str]) -> None:\n",
        "    text = path.read_text(encoding=\"utf-8\")\n",
        "    missing = [token for token in tokens if token not in text]\n",
        "    if missing:\n",
        "        raise AssertionError(f\"{path} missing expected tokens: {missing}\")\n",
        "\n",
        "must_contain(REPO_DIR / \"train.py\", [\"--profile\", \"--grad_accum_steps\", \"--amp\", \"--no_amp\"])\n",
        "must_contain(REPO_DIR / \"data\" / \"prepare_latents.py\", [\"--segment_seconds\", \"--max_files\", \"--dac_model_type\"])\n",
        "must_contain(REPO_DIR / \"inference\" / \"generate.py\", [\"--chunk_tokens\", \"--hop_tokens\", \"--steps\"])\n",
        "\n",
        "print(\"Sanity checks passed: expected CLI options are present.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "PROFILES = {\n",
        "    \"smoke\": {\n",
        "        \"prep\": {\"segment_seconds\": 2.0, \"max_files\": 2},\n",
        "        \"train\": {\n",
        "            \"epochs\": 1,\n",
        "            \"batch_size\": 2,\n",
        "            \"num_workers\": 2,\n",
        "            \"grad_accum_steps\": 1,\n",
        "            \"amp\": False,\n",
        "            \"log_interval\": 5,\n",
        "        },\n",
        "        \"infer\": {\"cfg\": 1.5, \"steps\": 8, \"chunk_tokens\": 64, \"hop_tokens\": 32},\n",
        "    },\n",
        "    \"poc\": {\n",
        "        \"prep\": {\"segment_seconds\": 5.0, \"max_files\": 80},\n",
        "        \"train\": {\n",
        "            \"epochs\": 8,\n",
        "            \"batch_size\": 4,\n",
        "            \"num_workers\": 2,\n",
        "            \"grad_accum_steps\": 4,\n",
        "            \"amp\": True,\n",
        "            \"log_interval\": 20,\n",
        "        },\n",
        "        \"infer\": {\"cfg\": 1.8, \"steps\": 24, \"chunk_tokens\": 192, \"hop_tokens\": 96},\n",
        "    },\n",
        "    \"full\": {\n",
        "        \"prep\": {\"segment_seconds\": 5.0, \"max_files\": -1},\n",
        "        \"train\": {\n",
        "            \"epochs\": 100,\n",
        "            \"batch_size\": 8,\n",
        "            \"num_workers\": 4,\n",
        "            \"grad_accum_steps\": 8,\n",
        "            \"amp\": True,\n",
        "            \"log_interval\": 50,\n",
        "        },\n",
        "        \"infer\": {\"cfg\": 2.0, \"steps\": 32, \"chunk_tokens\": 256, \"hop_tokens\": 128},\n",
        "    },\n",
        "}\n",
        "\n",
        "if PROFILE not in PROFILES:\n",
        "    raise ValueError(f\"Unsupported PROFILE '{PROFILE}'. Use one of: {list(PROFILES)}\")\n",
        "\n",
        "ACTIVE = PROFILES[PROFILE]\n",
        "print(json.dumps(ACTIVE, indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def run(cmd: list[str], cwd: Path | None = None) -> None:\n",
        "    print(\"+\", \" \".join(str(x) for x in cmd))\n",
        "    subprocess.run(cmd, check=True, cwd=str(cwd) if cwd else None)\n",
        "\n",
        "if RUN_PREP:\n",
        "    prep = ACTIVE[\"prep\"]\n",
        "    cmd = [\n",
        "        \"python\", \"-m\", \"data.prepare_latents\",\n",
        "        \"--source_dir\", str(Path(RAW_AUDIO_DIR)),\n",
        "        \"--out_dir\", str(PERSIST_LATENTS),\n",
        "        \"--dac_model_type\", DAC_MODEL_TYPE,\n",
        "        \"--segment_seconds\", str(prep[\"segment_seconds\"]),\n",
        "        \"--seed\", str(SEED),\n",
        "    ]\n",
        "    if prep[\"max_files\"] > 0:\n",
        "        cmd.extend([\"--max_files\", str(prep[\"max_files\"])])\n",
        "    run(cmd, cwd=REPO_DIR)\n",
        "else:\n",
        "    print(\"Skipping latent extraction (RUN_PREP=False)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def run(cmd: list[str], cwd: Path | None = None) -> None:\n",
        "    print(\"+\", \" \".join(str(x) for x in cmd))\n",
        "    subprocess.run(cmd, check=True, cwd=str(cwd) if cwd else None)\n",
        "\n",
        "if RUN_TRAIN:\n",
        "    train_cfg = ACTIVE[\"train\"]\n",
        "    cmd = [\n",
        "        \"torchrun\", \"--standalone\", \"--nnodes=1\", \"--nproc_per_node=1\", \"train.py\",\n",
        "        \"--profile\", PROFILE,\n",
        "        \"--data_dir\", str(PERSIST_LATENTS),\n",
        "        \"--checkpoint_dir\", str(PERSIST_CHECKPOINTS),\n",
        "        \"--epochs\", str(train_cfg[\"epochs\"]),\n",
        "        \"--batch_size\", str(train_cfg[\"batch_size\"]),\n",
        "        \"--num_workers\", str(train_cfg[\"num_workers\"]),\n",
        "        \"--grad_accum_steps\", str(train_cfg[\"grad_accum_steps\"]),\n",
        "        \"--log_interval\", str(train_cfg[\"log_interval\"]),\n",
        "        \"--seed\", str(SEED),\n",
        "    ]\n",
        "\n",
        "    if train_cfg[\"amp\"]:\n",
        "        cmd.append(\"--amp\")\n",
        "    else:\n",
        "        cmd.append(\"--no_amp\")\n",
        "\n",
        "    if RESUME_FROM_LATEST:\n",
        "        checkpoints = sorted(PERSIST_CHECKPOINTS.glob(\"checkpoint_epoch_*.pt\"))\n",
        "        if checkpoints:\n",
        "            cmd.extend([\"--resume_path\", str(checkpoints[-1])])\n",
        "            print(f\"Resuming from: {checkpoints[-1]}\")\n",
        "\n",
        "    run(cmd, cwd=REPO_DIR)\n",
        "else:\n",
        "    print(\"Skipping training (RUN_TRAIN=False)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def run(cmd: list[str], cwd: Path | None = None) -> None:\n",
        "    print(\"+\", \" \".join(str(x) for x in cmd))\n",
        "    subprocess.run(cmd, check=True, cwd=str(cwd) if cwd else None)\n",
        "\n",
        "if RUN_INFER:\n",
        "    infer_cfg = ACTIVE[\"infer\"]\n",
        "\n",
        "    if INFER_INPUT_WAV.strip():\n",
        "        input_wav = Path(INFER_INPUT_WAV)\n",
        "    else:\n",
        "        candidates = sorted(Path(RAW_AUDIO_DIR).glob(\"*.wav\"))\n",
        "        if not candidates:\n",
        "            raise FileNotFoundError(f\"No .wav files found in {RAW_AUDIO_DIR} and INFER_INPUT_WAV is empty.\")\n",
        "        input_wav = candidates[0]\n",
        "\n",
        "    checkpoint = PERSIST_CHECKPOINTS / \"checkpoint_best.pt\"\n",
        "    if not checkpoint.exists():\n",
        "        candidates = sorted(PERSIST_CHECKPOINTS.glob(\"checkpoint_epoch_*.pt\"))\n",
        "        if not candidates:\n",
        "            raise FileNotFoundError(\"No checkpoint found for inference.\")\n",
        "        checkpoint = candidates[-1]\n",
        "\n",
        "    output_wav = PERSIST_ARTIFACTS / f\"repaired_{input_wav.stem}_{PROFILE}.wav\"\n",
        "\n",
        "    cmd = [\n",
        "        \"python\", \"-m\", \"inference.generate\",\n",
        "        \"--input\", str(input_wav),\n",
        "        \"--output\", str(output_wav),\n",
        "        \"--checkpoint\", str(checkpoint),\n",
        "        \"--cfg\", str(infer_cfg[\"cfg\"]),\n",
        "        \"--steps\", str(infer_cfg[\"steps\"]),\n",
        "        \"--chunk_tokens\", str(infer_cfg[\"chunk_tokens\"]),\n",
        "        \"--hop_tokens\", str(infer_cfg[\"hop_tokens\"]),\n",
        "        \"--dac_model_type\", DAC_MODEL_TYPE,\n",
        "    ]\n",
        "    run(cmd, cwd=REPO_DIR)\n",
        "    print(f\"Saved: {output_wav}\")\n",
        "else:\n",
        "    print(\"Skipping inference (RUN_INFER=False)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "latent_files = sorted(PERSIST_LATENTS.glob(\"*.pt\"))\n",
        "checkpoint_files = sorted(PERSIST_CHECKPOINTS.glob(\"*.pt\"))\n",
        "artifact_wavs = sorted(PERSIST_ARTIFACTS.glob(\"*.wav\"))\n",
        "\n",
        "print(f\"Latent files: {len(latent_files)}\")\n",
        "print(f\"Checkpoint files: {len(checkpoint_files)}\")\n",
        "print(f\"Artifact wav files: {len(artifact_wavs)}\")\n",
        "\n",
        "if checkpoint_files:\n",
        "    print(\"Latest checkpoints:\")\n",
        "    for path in checkpoint_files[-5:]:\n",
        "        print(\" -\", path)\n",
        "\n",
        "if artifact_wavs:\n",
        "    print(\"Latest artifact wavs:\")\n",
        "    for path in artifact_wavs[-5:]:\n",
        "        print(\" -\", path)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
